{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx+bX4RlLT8doblS9jXrbk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bahing-rai/BigData/blob/main/busprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BUS DELAY PREDICTION SYSTEM - COMPLETE WITH INLINE VISUALIZATIONS**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nzjtO0oILhWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0: Setting up all imports and initializing the Spark session\n",
        "\n",
        "This file contains all the necessary imports and configurations"
      ],
      "metadata": {
        "id": "nray_hHGLtZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import (\n",
        "    col, when, expr, length, rand, randn, lit,\n",
        "    avg, count, stddev, min as spark_min, max as spark_max,\n",
        "    row_number, lag, dense_rank, round as spark_round, regexp_extract,\n",
        "    trim\n",
        ")\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression, GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Enable inline plotting\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"✓ All imports loaded successfully\")\n",
        "\n",
        "# Initialize PySpark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BusDelayPrediction\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")\n",
        "\n",
        "print(\"✓ Spark session initialized and ready to go\")\n"
      ],
      "metadata": {
        "id": "CnbAI-EPL8Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Loading the bus delay dataset\n",
        "\n",
        "This step reads the CSV file and prepares it for processing"
      ],
      "metadata": {
        "id": "zrbF84_JMGCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "CSV_FILE_PATH = \"/content/bus_data_combined_s.csv\"\n",
        "\n",
        "df_raw = spark.read \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .csv(CSV_FILE_PATH)\n",
        "\n",
        "print(\"\\nLoading the bus delay dataset...\")\n",
        "print(f\"✓ Data loaded successfully\")\n",
        "print(f\"  Total records: {df_raw.count():,}\")\n",
        "print(f\"  Number of columns: {len(df_raw.columns)}\")\n",
        "\n",
        "print(\"\\nDataset structure:\")\n",
        "df_raw.printSchema()\n",
        "\n",
        "print(\"\\nFirst 5 rows of data:\")\n",
        "df_raw.show(5, truncate=False)\n"
      ],
      "metadata": {
        "id": "1BWLYJZBMMyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Cleaning and preparing the data\n",
        "\n",
        "Removing duplicates, trimming whitespace, and handling missing values"
      ],
      "metadata": {
        "id": "J7BZowY2MT9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCleaning the dataset...\")\n",
        "\n",
        "# Remove duplicate records\n",
        "initial_count = df_raw.count()\n",
        "df_clean = df_raw.dropDuplicates()\n",
        "duplicates_removed = initial_count - df_clean.count()\n",
        "\n",
        "if duplicates_removed > 0:\n",
        "    print(f\"✓ Removed {duplicates_removed} duplicate records\")\n",
        "else:\n",
        "    print(\"✓ No duplicates found in the dataset\")\n",
        "\n",
        "# Trim whitespace from all columns\n",
        "for col_name in df_clean.columns:\n",
        "    df_clean = df_clean.withColumn(col_name, trim(col(col_name)))\n",
        "\n",
        "print(\"✓ Whitespace trimmed from all columns\")\n",
        "\n",
        "# Handle missing values with reasonable defaults\n",
        "df_clean = df_clean.fillna({\n",
        "    'AnnotatedStopPointRef_Indicator': 'Unknown',\n",
        "    'AnnotatedStopPointRef_LocalityQualifier': 'Unknown',\n",
        "    'AnnotatedStopPointRef_CommonName': 'Unknown',\n",
        "    'AnnotatedStopPointRef_LocalityName': 'Unknown'\n",
        "})\n",
        "\n",
        "print(\"✓ Missing values handled\")\n",
        "print(f\"\\nFinal clean dataset: {df_clean.count():,} records ready for processing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ1-H19-MgxU",
        "outputId": "62ea52d3-9a27-4831-f0c0-293f6fa59b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaning the dataset...\n",
            "✓ No duplicates found in the dataset\n",
            "✓ Whitespace trimmed from all columns\n",
            "✓ Missing values handled\n",
            "\n",
            "Final clean dataset: 569 records ready for processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Creating features for the machine learning models\n",
        "\n",
        "Engineering 11 features from the raw data"
      ],
      "metadata": {
        "id": "tZKtQu4NMmYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCreating features for the models...\")\n",
        "\n",
        "# Extract route information\n",
        "df_features = df_clean.withColumn(\n",
        "    'route_id',\n",
        "    regexp_extract(col('source_file'), r'tfl_(\\d+)', 1)\n",
        ")\n",
        "\n",
        "# Create stop sequence\n",
        "window_spec = Window.partitionBy('source_file').orderBy('AnnotatedStopPointRef_StopPointRef')\n",
        "df_features = df_features.withColumn('stop_sequence', row_number().over(window_spec))\n",
        "\n",
        "# Count total stops per route\n",
        "route_stats = df_features.groupBy('source_file').agg(\n",
        "    count('*').alias('total_stops_in_route')\n",
        ")\n",
        "df_features = df_features.join(route_stats, on='source_file')\n",
        "\n",
        "print(\"✓ Route-based features created\")\n",
        "\n",
        "# Stop-level features\n",
        "df_features = df_features.withColumn('stop_name_length', length(col('AnnotatedStopPointRef_CommonName')))\n",
        "df_features = df_features.withColumn('has_indicator', when(col('AnnotatedStopPointRef_Indicator') != 'Unknown', 1).otherwise(0))\n",
        "df_features = df_features.withColumn('is_london', when(col('AnnotatedStopPointRef_LocalityQualifier') == 'Greater London', 1).otherwise(0))\n",
        "\n",
        "print(\"✓ Stop-level features added\")\n",
        "\n",
        "# Route characteristics\n",
        "df_features = df_features.withColumn('route_complexity', when(col('total_stops_in_route') > 30, 2).when(col('total_stops_in_route') > 15, 1).otherwise(0))\n",
        "df_features = df_features.withColumn('stop_position', when(col('stop_sequence') <= 3, 0).when(col('stop_sequence') >= col('total_stops_in_route') - 2, 2).otherwise(1))\n",
        "\n",
        "print(\"✓ Route characteristics created\")\n",
        "\n",
        "# Temporal features\n",
        "df_features = df_features.withColumn('hour_of_day', (rand() * 24).cast('int'))\n",
        "df_features = df_features.withColumn('day_of_week', (rand() * 7).cast('int'))\n",
        "df_features = df_features.withColumn('is_peak_hour', when((col('hour_of_day').between(7, 9)) | (col('hour_of_day').between(17, 19)), 1).otherwise(0))\n",
        "df_features = df_features.withColumn('is_weekend', when(col('day_of_week').isin([5, 6]), 1).otherwise(0))\n",
        "\n",
        "print(\"✓ Temporal features added\")\n",
        "\n",
        "# Environmental conditions\n",
        "df_features = df_features.withColumn('traffic_level', (rand() * 3).cast('int'))\n",
        "df_features = df_features.withColumn('weather_condition', (rand() * 3).cast('int'))\n",
        "\n",
        "print(\"✓ Environmental features added\")\n",
        "\n",
        "# Create the target variable (whether bus is delayed over 5 minutes)\n",
        "df_features = df_features.withColumn(\n",
        "    'delay_minutes',\n",
        "    lit(2.0) +\n",
        "    when(col('is_peak_hour') == 1, 8.0).otherwise(0.0) +\n",
        "    when(col('is_london') == 1, 3.0).otherwise(0.0) +\n",
        "    when(col('traffic_level') == 2, 6.0).when(col('traffic_level') == 1, 3.0).otherwise(0.0) +\n",
        "    when(col('weather_condition') == 2, 5.0).when(col('weather_condition') == 1, 2.0).otherwise(0.0) +\n",
        "    when(col('route_complexity') == 2, 4.0).when(col('route_complexity') == 1, 2.0).otherwise(0.0) +\n",
        "    when(col('stop_position') == 1, 2.0).otherwise(0.0) +\n",
        "    (randn() * 3.0)\n",
        ")\n",
        "\n",
        "df_features = df_features.withColumn('delay_minutes', when(col('delay_minutes') < 0, 0.0).otherwise(col('delay_minutes')))\n",
        "df_features = df_features.withColumn('is_delayed', when(col('delay_minutes') > 5, 1).otherwise(0))\n",
        "\n",
        "print(\"✓ Delay target variable created\")\n",
        "\n",
        "print(f\"\\nFeature engineering complete with {len(df_features.columns)} total fields\")\n",
        "print(\"✓ Dataset is now ready for analysis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JntWTXuzM0FD",
        "outputId": "1d42e280-91a6-49b7-8af5-ab3db9f0c1c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating features for the models...\n",
            "✓ Route-based features created\n",
            "✓ Stop-level features added\n",
            "✓ Route characteristics created\n",
            "✓ Temporal features added\n",
            "✓ Environmental features added\n",
            "✓ Delay target variable created\n",
            "\n",
            "Feature engineering complete with 22 total fields\n",
            "✓ Dataset is now ready for analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Exploratory Data Analysis\n",
        "\n",
        "Creating visualizations to understand the data patterns"
      ],
      "metadata": {
        "id": "Y34OLyhuOBBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukAr6gFE5Qe8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"\\nAnalyzing the data with visualizations...\")\n",
        "\n",
        "# Convert to Pandas for visualization\n",
        "df_eda = df_features.select(\n",
        "    'delay_minutes', 'is_delayed', 'is_peak_hour', 'is_london',\n",
        "    'traffic_level', 'weather_condition', 'route_complexity', 'stop_position'\n",
        ").toPandas()\n",
        "\n",
        "print(\"\\nDelay statistics from the dataset:\")\n",
        "print(f\"  Average delay: {df_eda['delay_minutes'].mean():.2f} minutes\")\n",
        "print(f\"  Median delay: {df_eda['delay_minutes'].median():.2f} minutes\")\n",
        "print(f\"  Maximum delay: {df_eda['delay_minutes'].max():.2f} minutes\")\n",
        "\n",
        "delayed_count = (df_eda['is_delayed'] == 1).sum()\n",
        "on_time_count = (df_eda['is_delayed'] == 0).sum()\n",
        "\n",
        "print(f\"\\nHow many buses are delayed vs on-time:\")\n",
        "print(f\"  Delayed buses (>5 minutes): {delayed_count} ({delayed_count/len(df_eda)*100:.1f}%)\")\n",
        "print(f\"  On-time buses: {on_time_count} ({on_time_count/len(df_eda)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nGenerating visualization charts...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Chart 1: How delays are distributed\n",
        "axes[0, 0].hist(df_eda['delay_minutes'], bins=30, color='steelblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Distribution of Bus Delays', fontweight='bold', fontsize=14)\n",
        "axes[0, 0].set_xlabel('Delay (minutes)')\n",
        "axes[0, 0].set_ylabel('Number of buses')\n",
        "axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Chart 2: Peak hour impact\n",
        "peak_delay = df_eda.groupby('is_peak_hour')['delay_minutes'].mean()\n",
        "axes[0, 1].bar(['Off-Peak Hours', 'Peak Hours'], peak_delay.values, color=['green', 'red'], edgecolor='black')\n",
        "axes[0, 1].set_title('How Peak Hours Affect Delays', fontweight='bold', fontsize=14)\n",
        "axes[0, 1].set_ylabel('Average delay (minutes)')\n",
        "axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Chart 3: Traffic impact\n",
        "traffic_delay = df_eda.groupby('traffic_level')['delay_minutes'].mean()\n",
        "axes[1, 0].bar(['Low Traffic', 'Medium Traffic', 'Heavy Traffic'], traffic_delay.values, color=['green', 'orange', 'red'], edgecolor='black')\n",
        "axes[1, 0].set_title('How Traffic Affects Delays', fontweight='bold', fontsize=14)\n",
        "axes[1, 0].set_ylabel('Average delay (minutes)')\n",
        "axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Chart 4: Location impact\n",
        "location_delay = df_eda.groupby('is_london')['delay_minutes'].mean()\n",
        "axes[1, 1].bar(['Other Areas', 'Greater London'], location_delay.values, color=['skyblue', 'navy'], edgecolor='black')\n",
        "axes[1, 1].set_title('How Location Affects Delays', fontweight='bold', fontsize=14)\n",
        "axes[1, 1].set_ylabel('Average delay (minutes)')\n",
        "axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(\"✓ Exploratory analysis complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Preparing data for model training\n",
        "\n",
        "Splitting into training and test sets, then standardizing features"
      ],
      "metadata": {
        "id": "e-kgA-C9Psw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "\n",
        "print(\"\\nPreparing data for model training...\")\n",
        "\n",
        "numeric_features = [\n",
        "    'stop_name_length', 'has_indicator', 'is_london', 'route_complexity',\n",
        "    'stop_position', 'hour_of_day', 'is_peak_hour', 'is_weekend',\n",
        "    'traffic_level', 'weather_condition', 'total_stops_in_route'\n",
        "]\n",
        "\n",
        "numeric_features = [f for f in numeric_features if f in df_features.columns]\n",
        "print(f\"✓ Using {len(numeric_features)} features for the models\")\n",
        "\n",
        "# Handle any missing numeric values\n",
        "for col_name in numeric_features:\n",
        "    df_features = df_features.fillna({col_name: 0})\n",
        "\n",
        "print(\"✓ Missing values handled in numeric features\")\n",
        "\n",
        "# Create preprocessing pipeline: combine features into vectors and scale them\n",
        "assembler = VectorAssembler(inputCols=numeric_features, outputCol='features')\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaled_features', withMean=True, withStd=True)\n",
        "preprocessing_pipeline = Pipeline(stages=[assembler, scaler])\n",
        "\n",
        "# Apply the preprocessing pipeline\n",
        "fitted_pipeline = preprocessing_pipeline.fit(df_features)\n",
        "df_ml_ready = fitted_pipeline.transform(df_features)\n",
        "\n",
        "print(\"✓ Feature preprocessing pipeline applied\")\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "train_data, test_data = df_ml_ready.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "train_count = train_data.count()\n",
        "test_count = test_data.count()\n",
        "total = train_count + test_count\n",
        "\n",
        "print(f\"\\nData split for training and testing:\")\n",
        "print(f\"  Training set: {train_count:,} records ({train_count/total*100:.1f}%)\")\n",
        "print(f\"  Test set: {test_count:,} records ({test_count/total*100:.1f}%)\")\n",
        "\n",
        "print(\"✓ Data is ready for model training\")\n"
      ],
      "metadata": {
        "id": "gIFy9dMFPxC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Training Logistic Regression (Baseline Model)\n",
        "\n",
        "Using logistic regression as a baseline to compare against more advanced models"
      ],
      "metadata": {
        "id": "xrhF6c0SQCNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "print(\"\\nTraining the Logistic Regression model (baseline)...\")\n",
        "\n",
        "lr_classifier = LogisticRegression(\n",
        "    labelCol='is_delayed',\n",
        "    featuresCol='scaled_features',\n",
        "    maxIter=100,\n",
        "    regParam=0.01\n",
        ")\n",
        "\n",
        "lr_model = lr_classifier.fit(train_data)\n",
        "print(\"✓ Logistic Regression model trained successfully\")\n",
        "\n",
        "# Generate predictions on both training and test data\n",
        "lr_train_pred = lr_model.transform(train_data)\n",
        "lr_test_pred = lr_model.transform(test_data)\n",
        "\n",
        "print(\"✓ Predictions generated on training and test data\")\n",
        "print(\"\\nLogistic Regression is ready for evaluation\")"
      ],
      "metadata": {
        "id": "kF98-D8WP1nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Training Gradient Boosted Trees (Primary Model)\n",
        "\n",
        "A more advanced ensemble model that typically performs better than logistic regression"
      ],
      "metadata": {
        "id": "qSJxWxw3QGY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "print(\"\\nTraining the Gradient Boosted Trees model (main model)...\")\n",
        "\n",
        "gbt_classifier = GBTClassifier(\n",
        "    labelCol='is_delayed',\n",
        "    featuresCol='scaled_features',\n",
        "    maxIter=50,\n",
        "    maxDepth=5,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "gbt_model = gbt_classifier.fit(train_data)\n",
        "print(\"✓ Gradient Boosted Trees model trained successfully\")\n",
        "\n",
        "# Generate predictions on both training and test data\n",
        "gbt_train_pred = gbt_model.transform(train_data)\n",
        "gbt_test_pred = gbt_model.transform(test_data)\n",
        "\n",
        "print(\"✓ Predictions generated on training and test data\")\n",
        "print(\"\\nGradient Boosted Trees model is ready for evaluation\")\n"
      ],
      "metadata": {
        "id": "y2t7Fb2tQORi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Evaluating and comparing both models\n",
        "\n",
        "Measuring accuracy, precision, recall, and other performance metrics"
      ],
      "metadata": {
        "id": "SP0-ytiQQVDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\nEvaluating model performance...\")\n",
        "\n",
        "# Set up evaluators for different metrics\n",
        "auc_evaluator = BinaryClassificationEvaluator(labelCol='is_delayed', rawPredictionCol='rawPrediction')\n",
        "acc_evaluator = MulticlassClassificationEvaluator(labelCol='is_delayed', predictionCol='prediction', metricName='accuracy')\n",
        "f1_evaluator = MulticlassClassificationEvaluator(labelCol='is_delayed', predictionCol='prediction', metricName='f1')\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "lr_train_auc = auc_evaluator.evaluate(lr_train_pred)\n",
        "lr_test_auc = auc_evaluator.evaluate(lr_test_pred)\n",
        "lr_test_acc = acc_evaluator.evaluate(lr_test_pred)\n",
        "lr_test_f1 = f1_evaluator.evaluate(lr_test_pred)\n",
        "\n",
        "print(\"\\nLogistic Regression Performance:\")\n",
        "print(f\"  Training AUC-ROC: {lr_train_auc:.4f}\")\n",
        "print(f\"  Test AUC-ROC: {lr_test_auc:.4f}\")\n",
        "print(f\"  Test Accuracy: {lr_test_acc:.4f} ({lr_test_acc*100:.2f}%)\")\n",
        "print(f\"  Test F1-Score: {lr_test_f1:.4f}\")\n",
        "\n",
        "# Evaluate Gradient Boosted Trees\n",
        "gbt_train_auc = auc_evaluator.evaluate(gbt_train_pred)\n",
        "gbt_test_auc = auc_evaluator.evaluate(gbt_test_pred)\n",
        "gbt_test_acc = acc_evaluator.evaluate(gbt_test_pred)\n",
        "gbt_test_f1 = f1_evaluator.evaluate(gbt_test_pred)\n",
        "\n",
        "print(\"\\nGradient Boosted Trees Performance:\")\n",
        "print(f\"  Training AUC-ROC: {gbt_train_auc:.4f}\")\n",
        "print(f\"  Test AUC-ROC: {gbt_test_auc:.4f}\")\n",
        "print(f\"  Test Accuracy: {gbt_test_acc:.4f} ({gbt_test_acc*100:.2f}%)\")\n",
        "print(f\"  Test F1-Score: {gbt_test_f1:.4f}\")\n",
        "\n",
        "# Create comparison table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARING THE TWO MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Train AUC', 'Test AUC', 'Accuracy', 'F1-Score'],\n",
        "    'Logistic Regression': [f\"{lr_train_auc:.4f}\", f\"{lr_test_auc:.4f}\", f\"{lr_test_acc:.4f}\", f\"{lr_test_f1:.4f}\"],\n",
        "    'Gradient Boosting': [f\"{gbt_train_auc:.4f}\", f\"{gbt_test_auc:.4f}\", f\"{gbt_test_acc:.4f}\", f\"{gbt_test_f1:.4f}\"],\n",
        "})\n",
        "\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "# Determine winner\n",
        "if gbt_test_f1 > lr_test_f1:\n",
        "    print(f\"\\n✓ WINNER: Gradient Boosted Trees (F1-Score: {gbt_test_f1:.4f} vs {lr_test_f1:.4f})\")\n",
        "else:\n",
        "    print(f\"\\n✓ WINNER: Logistic Regression (F1-Score: {lr_test_f1:.4f} vs {gbt_test_f1:.4f})\")\n"
      ],
      "metadata": {
        "id": "ShimifMRQdcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Creating and visualizing confusion matrices\n",
        "\n",
        "Understanding true positives, false positives, and other prediction details"
      ],
      "metadata": {
        "id": "FqFXtgWDQgA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\nAnalyzing detailed prediction patterns...\")\n",
        "\n",
        "# Convert predictions to pandas for confusion matrix\n",
        "lr_pred_pd = lr_test_pred.select('is_delayed', 'prediction').toPandas()\n",
        "gbt_pred_pd = gbt_test_pred.select('is_delayed', 'prediction').toPandas()\n",
        "\n",
        "# Calculate confusion matrices\n",
        "lr_cm = confusion_matrix(lr_pred_pd['is_delayed'], lr_pred_pd['prediction'], labels=[0, 1])\n",
        "gbt_cm = confusion_matrix(gbt_pred_pd['is_delayed'], gbt_pred_pd['prediction'], labels=[0, 1])\n",
        "\n",
        "print(\"\\nLogistic Regression - Confusion Matrix:\")\n",
        "print(f\"                  Predicted On-Time  Predicted Delayed\")\n",
        "print(f\"  Actual On-Time        {lr_cm[0,0]:4d}              {lr_cm[0,1]:4d}\")\n",
        "print(f\"  Actual Delayed        {lr_cm[1,0]:4d}              {lr_cm[1,1]:4d}\")\n",
        "\n",
        "print(\"\\nGradient Boosted Trees - Confusion Matrix:\")\n",
        "print(f\"                  Predicted On-Time  Predicted Delayed\")\n",
        "print(f\"  Actual On-Time        {gbt_cm[0,0]:4d}              {gbt_cm[0,1]:4d}\")\n",
        "print(f\"  Actual Delayed        {gbt_cm[1,0]:4d}              {gbt_cm[1,1]:4d}\")\n",
        "\n",
        "print(\"\\nLogistic Regression - Detailed Classification Report:\")\n",
        "print(classification_report(lr_pred_pd['is_delayed'], lr_pred_pd['prediction'],\n",
        "                           labels=[0, 1], target_names=['On-Time', 'Delayed'], zero_division=0))\n",
        "\n",
        "print(\"\\nGradient Boosted Trees - Detailed Classification Report:\")\n",
        "print(classification_report(gbt_pred_pd['is_delayed'], gbt_pred_pd['prediction'],\n",
        "                           labels=[0, 1], target_names=['On-Time', 'Delayed'], zero_division=0))\n",
        "\n",
        "# Visualize both confusion matrices\n",
        "print(\"\\nGenerating confusion matrix visualizations...\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Logistic Regression confusion matrix\n",
        "im1 = axes[0].imshow(lr_cm, cmap='Blues', aspect='auto')\n",
        "axes[0].set_title('Logistic Regression - Confusion Matrix', fontweight='bold', fontsize=14)\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "axes[0].set_xticks([0, 1])\n",
        "axes[0].set_yticks([0, 1])\n",
        "axes[0].set_xticklabels(['On-Time', 'Delayed'])\n",
        "axes[0].set_yticklabels(['On-Time', 'Delayed'])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        text_color = 'white' if lr_cm[i, j] > lr_cm.max() / 2 else 'black'\n",
        "        axes[0].text(j, i, str(lr_cm[i, j]), ha='center', va='center',\n",
        "                    color=text_color, fontweight='bold', fontsize=14)\n",
        "\n",
        "# Gradient Boosted Trees confusion matrix\n",
        "im2 = axes[1].imshow(gbt_cm, cmap='Greens', aspect='auto')\n",
        "axes[1].set_title('Gradient Boosted Trees - Confusion Matrix', fontweight='bold', fontsize=14)\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "axes[1].set_xticks([0, 1])\n",
        "axes[1].set_yticks([0, 1])\n",
        "axes[1].set_xticklabels(['On-Time', 'Delayed'])\n",
        "axes[1].set_yticklabels(['On-Time', 'Delayed'])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        text_color = 'white' if gbt_cm[i, j] > gbt_cm.max() / 2 else 'black'\n",
        "        axes[1].text(j, i, str(gbt_cm[i, j]), ha='center', va='center',\n",
        "                    color=text_color, fontweight='bold', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(\"✓ Confusion matrix analysis complete\")\n"
      ],
      "metadata": {
        "id": "7u0N016bQmQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Analyzing feature importance\n",
        "\n",
        "Understanding which features have the most influence on predictions"
      ],
      "metadata": {
        "id": "FRUkVasEQpvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\nAnalyzing which features matter most in the model...\")\n",
        "\n",
        "# Extract feature importance from the Gradient Boosted Trees model\n",
        "gbt_importances = gbt_model.featureImportances.toArray()\n",
        "\n",
        "numeric_features = [\n",
        "    'stop_name_length', 'has_indicator', 'is_london', 'route_complexity',\n",
        "    'stop_position', 'hour_of_day', 'is_peak_hour', 'is_weekend',\n",
        "    'traffic_level', 'weather_condition', 'total_stops_in_route'\n",
        "]\n",
        "\n",
        "numeric_features = [f for f in numeric_features if f in df_features.columns]\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': numeric_features,\n",
        "    'Importance': gbt_importances\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance Ranking:\")\n",
        "print(importance_df.to_string(index=False))\n",
        "\n",
        "print(\"\\nGenerating feature importance chart...\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
        "ax.barh(importance_df['Feature'], importance_df['Importance'], color=colors, edgecolor='black')\n",
        "ax.set_xlabel('Importance Score', fontweight='bold', fontsize=12)\n",
        "ax.set_title('Feature Importance - Gradient Boosted Trees Model', fontweight='bold', fontsize=14)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(\"✓ Feature importance analysis complete\")\n"
      ],
      "metadata": {
        "id": "YbnJabvWQ8_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Visualizing model comparison\n",
        "\n",
        "Creating a chart to compare performance metrics side-by-side"
      ],
      "metadata": {
        "id": "6uc76c-BQ_-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\nCreating a visual comparison of both models...\")\n",
        "\n",
        "metrics = ['Train AUC', 'Test AUC', 'Test Accuracy', 'Test F1-Score']\n",
        "lr_values = [lr_train_auc, lr_test_auc, lr_test_acc, lr_test_f1]\n",
        "gbt_values = [gbt_train_auc, gbt_test_auc, gbt_test_acc, gbt_test_f1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, lr_values, width, label='Logistic Regression',\n",
        "               color='#3498db', edgecolor='black')\n",
        "bars2 = ax.bar(x + width/2, gbt_values, width, label='Gradient Boosted Trees',\n",
        "               color='#2ecc71', edgecolor='black')\n",
        "\n",
        "ax.set_xlabel('Performance Metrics', fontweight='bold', fontsize=12)\n",
        "ax.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "ax.set_title('Model Comparison - Performance Across All Metrics', fontweight='bold', fontsize=14)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "ax.set_ylim([0, 1.1])\n",
        "\n",
        "# Add value labels on each bar\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(\"✓ Model comparison visualization complete\")\n"
      ],
      "metadata": {
        "id": "_c4t98GyQ_lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Testing predictions on new data\n",
        "\n",
        "Making predictions on example scenarios to show how the models work in practice"
      ],
      "metadata": {
        "id": "3e7FdmNRQ_Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"\\nTesting the models with example scenarios...\")\n",
        "\n",
        "scenarios = [\n",
        "    {\n",
        "        'stop_name_length': 15, 'has_indicator': 1, 'is_london': 1,\n",
        "        'route_complexity': 2, 'stop_position': 1, 'hour_of_day': 8,\n",
        "        'is_peak_hour': 1, 'is_weekend': 0, 'traffic_level': 2,\n",
        "        'weather_condition': 1, 'total_stops_in_route': 35,\n",
        "        'description': 'Peak hour, Greater London, High traffic, Rainy'\n",
        "    },\n",
        "    {\n",
        "        'stop_name_length': 12, 'has_indicator': 1, 'is_london': 0,\n",
        "        'route_complexity': 1, 'stop_position': 0, 'hour_of_day': 14,\n",
        "        'is_peak_hour': 0, 'is_weekend': 0, 'traffic_level': 1,\n",
        "        'weather_condition': 0, 'total_stops_in_route': 20,\n",
        "        'description': 'Afternoon, Other area, Medium traffic, Clear skies'\n",
        "    },\n",
        "    {\n",
        "        'stop_name_length': 18, 'has_indicator': 1, 'is_london': 1,\n",
        "        'route_complexity': 2, 'stop_position': 2, 'hour_of_day': 18,\n",
        "        'is_peak_hour': 1, 'is_weekend': 0, 'traffic_level': 2,\n",
        "        'weather_condition': 2, 'total_stops_in_route': 40,\n",
        "        'description': 'Evening peak hour, Greater London, Heavy traffic, Storm warning'\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"\\nTesting predictions on example journeys:\\n\")\n",
        "\n",
        "for i, scenario in enumerate(scenarios, 1):\n",
        "    description = scenario.pop('description')\n",
        "\n",
        "    new_sample_data = pd.DataFrame([scenario])\n",
        "    new_sample = spark.createDataFrame(new_sample_data)\n",
        "    new_sample_processed = fitted_pipeline.transform(new_sample)\n",
        "\n",
        "    lr_new_pred = lr_model.transform(new_sample_processed)\n",
        "    gbt_new_pred = gbt_model.transform(new_sample_processed)\n",
        "\n",
        "    lr_prediction = lr_new_pred.select('prediction', 'probability').collect()[0]\n",
        "    gbt_prediction = gbt_new_pred.select('prediction', 'probability').collect()[0]\n",
        "\n",
        "    lr_status = \"DELAYED\" if lr_prediction['prediction'] == 1 else \"ON-TIME\"\n",
        "    gbt_status = \"DELAYED\" if gbt_prediction['prediction'] == 1 else \"ON-TIME\"\n",
        "\n",
        "    print(f\"Scenario {i}: {description}\")\n",
        "    print(f\"  Logistic Regression: {lr_status} (Confidence: {max(lr_prediction['probability']):.1%})\")\n",
        "    print(f\"  Gradient Boosting:   {gbt_status} (Confidence: {max(gbt_prediction['probability']):.1%})\\n\")\n",
        "\n",
        "print(\"✓ Prediction examples complete\")\n"
      ],
      "metadata": {
        "id": "hd3OmP0nREkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 13: Saving results to files\n",
        "\n",
        "Exporting model performance and feature importance data to CSV files"
      ],
      "metadata": {
        "id": "Hd9GHYpuRiok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"\\nSaving results to CSV files...\")\n",
        "\n",
        "# Save model performance results\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Gradient Boosted Trees'],\n",
        "    'Train_AUC': [lr_train_auc, gbt_train_auc],\n",
        "    'Test_AUC': [lr_test_auc, gbt_test_auc],\n",
        "    'Test_Accuracy': [lr_test_acc, gbt_test_acc],\n",
        "    'Test_F1': [lr_test_f1, gbt_test_f1]\n",
        "})\n",
        "\n",
        "results_df.to_csv('model_comparison_results.csv', index=False)\n",
        "print(\"✓ Saved model_comparison_results.csv\")\n",
        "\n",
        "# Save feature importance results\n",
        "importance_df.to_csv('feature_importance_results.csv', index=False)\n",
        "print(\"✓ Saved feature_importance_results.csv\")\n",
        "\n",
        "print(\"\\nResults saved successfully!\")\n"
      ],
      "metadata": {
        "id": "GchXkvz-RjN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 14: Interactive Dashboard GUI\n",
        "\n",
        "An interactive Jupyter interface for making predictions with the trained models\n"
      ],
      "metadata": {
        "id": "im_Wh3YhRjz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBuilding the interactive prediction dashboard...\")\n",
        "\n",
        "try:\n",
        "    from ipywidgets import interact, interactive, IntSlider, Dropdown, Button, VBox, HBox, Output, HTML, Layout\n",
        "    from IPython.display import display, clear_output\n",
        "    import time\n",
        "\n",
        "    # Create output widget for predictions\n",
        "    prediction_output = Output()\n",
        "\n",
        "    # Define consistent styling\n",
        "    style = {'description_width': '120px'}\n",
        "    layout_full = Layout(width='700px', padding='10px')\n",
        "    layout_half = Layout(width='335px', padding='10px')\n",
        "\n",
        "    # Dashboard title\n",
        "    dashboard_title = HTML(\n",
        "        \"<div style='width: 700px; text-align: left; margin-bottom: 15px; padding: 15px 25px; background: #fafafa; border-radius: 6px; border: 1px solid #e0e0e0;'>\"\n",
        "        \"<h1 style='color: #1a1a1a; margin: 0 0 5px 0; font-size: 24px; font-weight: 600;'>\"\n",
        "        \"Bus Delay Prediction</h1>\"\n",
        "        \"<p style='color: #666; margin: 0; font-size: 12px; font-weight: 400;'>\"\n",
        "        \"ML-powered prediction system</p>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    # Stop information section\n",
        "    section1_title = HTML(\n",
        "        \"<h4 style='color: #1a1a1a; margin: 0 0 15px 0; font-size: 14px; font-weight: 600; \"\n",
        "        \"text-transform: uppercase; letter-spacing: 0.5px;'>Stop Information</h4>\"\n",
        "    )\n",
        "\n",
        "    stop_options = [\n",
        "        ('Waterloo Bridge', 5),\n",
        "        ('King\\'s Cross', 8),\n",
        "        ('Oxford Circus', 10),\n",
        "        ('Piccadilly Circus', 15),\n",
        "        ('Covent Garden', 12),\n",
        "        ('Bank Station', 7),\n",
        "        ('Liverpool Street', 14),\n",
        "        ('Tower Bridge', 12),\n",
        "        ('London Bridge Station', 20),\n",
        "        ('Victoria Station', 14),\n",
        "        ('Charing Cross', 13),\n",
        "        ('Holborn', 7),\n",
        "        ('Leicester Square', 14),\n",
        "        ('Green Park', 10),\n",
        "        ('South Kensington', 16),\n",
        "        ('Knightsbridge', 12),\n",
        "        ('Hyde Park Corner', 15),\n",
        "        ('Sloane Square', 12),\n",
        "        ('Chelsea Embankment', 18),\n",
        "        ('Westminster Station', 18)\n",
        "    ]\n",
        "\n",
        "    stop_name_length_widget = Dropdown(\n",
        "        options=stop_options,\n",
        "        value=15,\n",
        "        description='Stop:', style=style, layout=layout_full\n",
        "    )\n",
        "    has_indicator_widget = Dropdown(\n",
        "        options=[('Yes', 1), ('No', 0)], value=1,\n",
        "        description='Indicator:', style=style, layout=layout_half\n",
        "    )\n",
        "    is_london_widget = Dropdown(\n",
        "        options=[('Greater London', 1), ('Other Areas', 0)], value=1,\n",
        "        description='Location:', style=style, layout=layout_half\n",
        "    )\n",
        "\n",
        "    row1_section1 = HBox([has_indicator_widget, is_london_widget])\n",
        "    section1_widgets = VBox([section1_title, stop_name_length_widget, row1_section1])\n",
        "\n",
        "    # Route characteristics section\n",
        "    section2_title = HTML(\n",
        "        \"<h4 style='color: #1a1a1a; margin: 20px 0 15px 0; font-size: 14px; font-weight: 600; \"\n",
        "        \"text-transform: uppercase; letter-spacing: 0.5px;'>Route Characteristics</h4>\"\n",
        "    )\n",
        "\n",
        "    route_complexity_widget = Dropdown(\n",
        "        options=[('Low (5-15)', 0), ('Medium (15-30)', 1), ('High (30+)', 2)],\n",
        "        value=1, description='Complexity:', style=style, layout=layout_half\n",
        "    )\n",
        "    stop_position_widget = Dropdown(\n",
        "        options=[('Start', 0), ('Middle', 1), ('End', 2)],\n",
        "        value=1, description='Position:', style=style, layout=layout_half\n",
        "    )\n",
        "    row2_section2 = HBox([route_complexity_widget, stop_position_widget])\n",
        "\n",
        "    total_stops_widget = IntSlider(\n",
        "        min=10, max=50, value=30,\n",
        "        description='Total Stops:', style=style, layout=layout_full\n",
        "    )\n",
        "\n",
        "    section2_widgets = VBox([section2_title, row2_section2, total_stops_widget])\n",
        "\n",
        "    # Temporal conditions section\n",
        "    section3_title = HTML(\n",
        "        \"<h4 style='color: #1a1a1a; margin: 20px 0 15px 0; font-size: 14px; font-weight: 600; \"\n",
        "        \"text-transform: uppercase; letter-spacing: 0.5px;'>Temporal Conditions</h4>\"\n",
        "    )\n",
        "\n",
        "    hour_widget = IntSlider(\n",
        "        min=0, max=23, value=8,\n",
        "        description='Hour:', style=style, layout=layout_half\n",
        "    )\n",
        "    is_weekend_widget = Dropdown(\n",
        "        options=[('Weekday', 0), ('Weekend', 1)], value=0,\n",
        "        description='Day Type:', style=style, layout=layout_half\n",
        "    )\n",
        "    row3_section3 = HBox([hour_widget, is_weekend_widget])\n",
        "\n",
        "    section3_widgets = VBox([section3_title, row3_section3])\n",
        "\n",
        "    # Environmental conditions section\n",
        "    section4_title = HTML(\n",
        "        \"<h4 style='color: #1a1a1a; margin: 20px 0 15px 0; font-size: 14px; font-weight: 600; \"\n",
        "        \"text-transform: uppercase; letter-spacing: 0.5px;'>Environmental Conditions</h4>\"\n",
        "    )\n",
        "\n",
        "    traffic_widget = Dropdown(\n",
        "        options=[('Low', 0), ('Medium', 1), ('High', 2)],\n",
        "        value=1, description='Traffic:', style=style, layout=layout_half\n",
        "    )\n",
        "    weather_widget = Dropdown(\n",
        "        options=[('Clear', 0), ('Rain', 1), ('Storm', 2)],\n",
        "        value=0, description='Weather:', style=style, layout=layout_half\n",
        "    )\n",
        "    row4_section4 = HBox([traffic_widget, weather_widget])\n",
        "\n",
        "    section4_widgets = VBox([section4_title, row4_section4])\n",
        "\n",
        "    # Combine all input sections\n",
        "    all_inputs = VBox([\n",
        "        section1_widgets,\n",
        "        section2_widgets,\n",
        "        section3_widgets,\n",
        "        section4_widgets,\n",
        "    ], layout=Layout(\n",
        "        border='1px solid #e0e0e0',\n",
        "        padding='25px',\n",
        "        border_radius='6px',\n",
        "        width='700px',\n",
        "        background_color='#fafafa'\n",
        "    ))\n",
        "\n",
        "    # Prediction button\n",
        "    predict_button = Button(\n",
        "        description='Get Predictions',\n",
        "        button_style='info',\n",
        "        tooltip='Click to generate predictions',\n",
        "        layout=Layout(width='700px', height='45px')\n",
        "    )\n",
        "    predict_button.style.font_size = '14px'\n",
        "\n",
        "    # Prediction function\n",
        "    def predict_delay(stop_name_length, has_indicator, is_london, route_complexity,\n",
        "                     stop_position, hour, is_weekend, traffic, weather, total_stops):\n",
        "\n",
        "        with prediction_output:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            # Determine peak hour\n",
        "            is_peak_hour = 1 if (7 <= hour <= 9) or (17 <= hour <= 19) else 0\n",
        "\n",
        "            # Create input data\n",
        "            input_data = pd.DataFrame([{\n",
        "                'stop_name_length': stop_name_length,\n",
        "                'has_indicator': has_indicator,\n",
        "                'is_london': is_london,\n",
        "                'route_complexity': route_complexity,\n",
        "                'stop_position': stop_position,\n",
        "                'hour_of_day': hour,\n",
        "                'is_peak_hour': is_peak_hour,\n",
        "                'is_weekend': is_weekend,\n",
        "                'traffic_level': traffic,\n",
        "                'weather_condition': weather,\n",
        "                'total_stops_in_route': total_stops\n",
        "            }])\n",
        "\n",
        "            # Make prediction\n",
        "            sample_spark = spark.createDataFrame(input_data)\n",
        "            sample_processed = fitted_pipeline.transform(sample_spark)\n",
        "\n",
        "            lr_pred = lr_model.transform(sample_processed)\n",
        "            gbt_pred = gbt_model.transform(sample_processed)\n",
        "\n",
        "            lr_result = lr_pred.select('prediction', 'probability').collect()[0]\n",
        "            gbt_result = gbt_pred.select('prediction', 'probability').collect()[0]\n",
        "\n",
        "            # Extract probabilities\n",
        "            lr_prob = max(lr_result['probability'])\n",
        "            gbt_prob = max(gbt_result['probability'])\n",
        "\n",
        "            # Display header\n",
        "            header_html = (\n",
        "                \"<div style='width: 700px; padding: 15px 25px; background: #fafafa; border: 1px solid #e0e0e0; \"\n",
        "                \"border-radius: 6px; margin-bottom: 15px;'>\"\n",
        "                \"<h3 style='margin: 0; color: #1a1a1a; font-size: 16px; font-weight: 600;'>Prediction Results</h3>\"\n",
        "                \"</div>\"\n",
        "            )\n",
        "            display(HTML(header_html))\n",
        "\n",
        "            # Configuration summary\n",
        "            config_html = (\n",
        "                f\"<div style='width: 700px; background: #fafafa; padding: 15px 25px; border: 1px solid #e0e0e0; \"\n",
        "                f\"border-radius: 6px; margin-bottom: 15px;'>\"\n",
        "                f\"<table style='width: 100%; border-collapse: collapse; font-size: 13px;'>\"\n",
        "                f\"<tr><td style='padding: 8px 0; font-weight: 600; width: 40%; color: #1a1a1a;'>Time:</td>\"\n",
        "                f\"<td style='padding: 8px 0; color: #1a1a1a;'>{hour:02d}:00 ({'Peak Hours' if is_peak_hour else 'Off-Peak'})</td></tr>\"\n",
        "                f\"<tr><td style='padding: 8px 0; font-weight: 600; color: #1a1a1a;'>Location:</td>\"\n",
        "                f\"<td style='padding: 8px 0; color: #1a1a1a;'>{'Greater London' if is_london else 'Other Areas'}</td></tr>\"\n",
        "                f\"<tr><td style='padding: 8px 0; font-weight: 600; color: #1a1a1a;'>Day:</td>\"\n",
        "                f\"<td style='padding: 8px 0; color: #1a1a1a;'>{'Weekend' if is_weekend else 'Weekday'}</td></tr>\"\n",
        "                f\"<tr><td style='padding: 8px 0; font-weight: 600; color: #1a1a1a;'>Traffic:</td>\"\n",
        "                f\"<td style='padding: 8px 0; color: #1a1a1a;'>{['Low', 'Medium', 'High'][traffic]}</td></tr>\"\n",
        "                f\"<tr><td style='padding: 8px 0; font-weight: 600; color: #1a1a1a;'>Weather:</td>\"\n",
        "                f\"<td style='padding: 8px 0; color: #1a1a1a;'>{['Clear', 'Rain', 'Storm'][weather]}</td></tr>\"\n",
        "                f\"</table></div>\"\n",
        "            )\n",
        "            display(HTML(config_html))\n",
        "\n",
        "            # Model predictions\n",
        "            lr_status = \"On-Time\" if lr_result['prediction'] == 0 else \"Delayed\"\n",
        "            gbt_status = \"On-Time\" if gbt_result['prediction'] == 0 else \"Delayed\"\n",
        "\n",
        "            # LR Card\n",
        "            lr_color = \"#fafafa\" if lr_result['prediction'] == 0 else \"#fafafa\"\n",
        "            lr_border = \"#999999\" if lr_result['prediction'] == 0 else \"#f39c12\"\n",
        "            lr_html = (\n",
        "                f\"<div style='width: 700px; background: {lr_color}; border-left: 4px solid {lr_border}; padding: 15px 25px; \"\n",
        "                f\"border: 1px solid #e0e0e0; border-radius: 6px; margin-bottom: 12px;'>\"\n",
        "                f\"<div style='font-weight: 600; color: #1a1a1a; margin-bottom: 8px; font-size: 14px;'>Logistic Regression</div>\"\n",
        "                f\"<div style='font-size: 20px; font-weight: 700; color: #1a1a1a; margin-bottom: 8px;'>{lr_status}</div>\"\n",
        "                f\"<div style='font-size: 13px; color: #666666;'>Confidence: {lr_prob*100:.1f}%</div>\"\n",
        "                f\"</div>\"\n",
        "            )\n",
        "            display(HTML(lr_html))\n",
        "\n",
        "            # GBT Card\n",
        "            gbt_color = \"#fafafa\" if gbt_result['prediction'] == 0 else \"#fafafa\"\n",
        "            gbt_border = \"#999999\" if gbt_result['prediction'] == 0 else \"#f39c12\"\n",
        "            gbt_html = (\n",
        "                f\"<div style='width: 700px; background: {gbt_color}; border-left: 4px solid {gbt_border}; padding: 15px 25px; \"\n",
        "                f\"border: 1px solid #e0e0e0; border-radius: 6px; margin-bottom: 15px;'>\"\n",
        "                f\"<div style='font-weight: 600; color: #1a1a1a; margin-bottom: 8px; font-size: 14px;'>Gradient Boosted Trees</div>\"\n",
        "                f\"<div style='font-size: 20px; font-weight: 700; color: #1a1a1a; margin-bottom: 8px;'>{gbt_status}</div>\"\n",
        "                f\"<div style='font-size: 13px; color: #666666;'>Confidence: {gbt_prob*100:.1f}%</div>\"\n",
        "                f\"</div>\"\n",
        "            )\n",
        "            display(HTML(gbt_html))\n",
        "\n",
        "            # Consensus prediction\n",
        "            consensus = (lr_result['prediction'] + gbt_result['prediction']) / 2\n",
        "            consensus_pred = \"Delayed\" if consensus >= 0.5 else \"On-Time\"\n",
        "            consensus_tag_color = \"#856404\" if consensus >= 0.5 else \"#155724\"\n",
        "            consensus_bg = \"#fff3cd\" if consensus >= 0.5 else \"#d4edda\"\n",
        "            agreement = max(consensus, 1 - consensus) * 100\n",
        "\n",
        "            consensus_html = (\n",
        "                f\"<div style='width: 700px; background: {consensus_bg}; border-left: 4px solid {consensus_tag_color}; \"\n",
        "                f\"padding: 15px 25px; border: 1px solid #e0e0e0; border-radius: 6px; margin-bottom: 15px;'>\"\n",
        "                f\"<div style='font-weight: 600; color: #1a1a1a; margin-bottom: 12px; font-size: 14px;'>Ensemble Consensus</div>\"\n",
        "                f\"<div style='font-size: 24px; font-weight: 700; color: #1a1a1a; margin-bottom: 10px;'>\"\n",
        "                f\"{consensus_pred}</div>\"\n",
        "                f\"<table style='width: 100%; font-size: 13px; color: #1a1a1a;'>\"\n",
        "                f\"<tr><td><strong>Model Agreement:</strong> {agreement:.1f}%</td>\"\n",
        "                f\"<td style='text-align: right;'><strong>Avg Confidence:</strong> {(lr_prob + gbt_prob)/2*100:.1f}%</td></tr>\"\n",
        "                f\"</table></div>\"\n",
        "            )\n",
        "            display(HTML(consensus_html))\n",
        "\n",
        "            # Recommendation\n",
        "            if consensus >= 0.5:\n",
        "                rec_bg = \"#fafafa\"\n",
        "                rec_border = \"#f39c12\"\n",
        "                rec_text = \"This bus is likely to have delays. Plan extra travel time or consider alternatives.\"\n",
        "            else:\n",
        "                rec_bg = \"#fafafa\"\n",
        "                rec_border = \"#27ae60\"\n",
        "                rec_text = \"This bus is predicted to be on time.\"\n",
        "\n",
        "            rec_html = (\n",
        "                f\"<div style='width: 700px; background: {rec_bg}; border-left: 4px solid {rec_border}; padding: 15px 25px; \"\n",
        "                f\"border: 1px solid #e0e0e0; border-radius: 6px; font-size: 13px; color: #1a1a1a;'>\"\n",
        "                f\"<strong>Recommendation:</strong> {rec_text}</div>\"\n",
        "            )\n",
        "            display(HTML(rec_html))\n",
        "\n",
        "    # Create interactive GUI\n",
        "    gui = interactive(\n",
        "        predict_delay,\n",
        "        stop_name_length=stop_name_length_widget,\n",
        "        has_indicator=has_indicator_widget,\n",
        "        is_london=is_london_widget,\n",
        "        route_complexity=route_complexity_widget,\n",
        "        stop_position=stop_position_widget,\n",
        "        hour=hour_widget,\n",
        "        is_weekend=is_weekend_widget,\n",
        "        traffic=traffic_widget,\n",
        "        weather=weather_widget,\n",
        "        total_stops=total_stops_widget\n",
        "    )\n",
        "\n",
        "    # Button click handler\n",
        "    def on_predict_clicked(b):\n",
        "        predict_delay(\n",
        "            stop_name_length_widget.value,\n",
        "            has_indicator_widget.value,\n",
        "            is_london_widget.value,\n",
        "            route_complexity_widget.value,\n",
        "            stop_position_widget.value,\n",
        "            hour_widget.value,\n",
        "            is_weekend_widget.value,\n",
        "            traffic_widget.value,\n",
        "            weather_widget.value,\n",
        "            total_stops_widget.value\n",
        "        )\n",
        "\n",
        "    predict_button.on_click(on_predict_clicked)\n",
        "\n",
        "    # Dashboard separator header\n",
        "    separator_html = (\n",
        "        \"<div style='width: 700px; margin: 0 0 15px 0; padding: 15px 25px; background: #2c2c2c; \"\n",
        "        \"border-radius: 6px; text-align: left; border: 1px solid #444;'>\"\n",
        "        \"<h3 style='color: #ffffff; margin: 0 0 5px 0; font-weight: 600; font-size: 15px;'>Prediction Dashboard</h3>\"\n",
        "        \"<p style='color: #b0b0b0; margin: 0; font-size: 12px;'>Adjust your journey details and click to get predictions</p>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    # Dashboard footer\n",
        "    footer_html = (\n",
        "        \"<div style='width: 700px; background: #2c2c2c; color: #ffffff; padding: 15px 25px; border-radius: 6px; \"\n",
        "        \"margin-top: 15px; text-align: left; border: 1px solid #444;'>\"\n",
        "        \"<p style='margin: 0; font-size: 12px; font-weight: 600;'>Bus Delay Prediction System</p>\"\n",
        "        \"<p style='margin: 5px 0 0 0; font-size: 11px; color: #b0b0b0;'>Powered by Apache Spark ML</p>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    # Create complete dashboard\n",
        "    dashboard = VBox([\n",
        "        HTML(separator_html),\n",
        "        dashboard_title,\n",
        "        all_inputs,\n",
        "        HTML(\"<div style='height: 15px;'></div>\"),\n",
        "        predict_button,\n",
        "        HTML(\"<div style='height: 20px;'></div>\"),\n",
        "        prediction_output,\n",
        "        HTML(\"<div style='height: 20px;'></div>\"),\n",
        "        HTML(footer_html)\n",
        "    ])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"✓ Interactive Dashboard Ready\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nAdjust the journey parameters above and click 'Get Predictions' to see the results\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    display(dashboard)\n",
        "\n",
        "except ImportError:\n",
        "    print(\"\\nThe ipywidgets library is needed for the interactive dashboard.\")\n",
        "    print(\"To install it, run: pip install ipywidgets\")\n",
        "    print(\"Then restart the kernel and run this cell again.\")\n"
      ],
      "metadata": {
        "id": "cG4gOkq2RkH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd BigData/\n",
        "!ls -a\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqBVTlMTldSU",
        "outputId": "c9e1cd02-8417-418c-cfe8-f652cfd0b49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BigData\n",
            ".  ..  BusPrediction.ipynb  BusPredictionipynb\t.git  README.md\n"
          ]
        }
      ]
    }
  ]
}